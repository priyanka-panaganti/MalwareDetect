from flask import Flask, request, jsonify
import pandas as pd
from androguard.core.bytecodes.apk import APK
from androguard.core.bytecodes.dvm import DalvikVMFormat
import re
import pickle
import os

app = Flask(__name__)

# Load the trained Random Forest model
with open('model.pkl', 'rb') as model_file:
    rf_model = pickle.load(model_file)

# Define the feature extraction function
def extract_features(apk_file_path, feature_df,data):
    permissions_list = feature_df[feature_df["Category"] == "Manifest Permission"].X.unique()
    api_call_signatures = feature_df[feature_df["Category"] == "API call signature"].X.unique()
    intents = feature_df[feature_df["Category"] == "Intent"].X.unique()
    keywords = feature_df[feature_df["Category"] == "Commands signature"].X.unique()
    # Initialize a DataFrame to store the extracted features
    columns = ["filename"] 
    for col in data.columns:
        columns.append(col)

    test_df = pd.DataFrame(columns=columns)

    test_df.loc[0, "filename"] = apk_file_path
    test_df.head()
    
    # Load APK file and extract features
    a = APK(apk_file_path)
    d = DalvikVMFormat(a.get_dex())
    permissions = a.get_permissions()
    manifest = a.get_android_manifest_xml()
    intent_filters = manifest.findall(".//intent-filter")
    
    # Extract permissions
    found_permissions = []
    found_api_signatures = []
    found_intents = []
    found_keywords = []
    # Extract API call signatures
  
    for permission in permissions:
        permission = permission.split(".")[-1]
        if permission in permissions_list:
            found_permissions.append(permission)
    
    for permission in permissions_list:
        if permission in found_permissions:
            test_df[permission] = 1
        else:
            test_df[permission] = 0
    for method in d.get_methods():
        for api_call in api_call_signatures:
            if re.search(api_call, method.get_descriptor()):
            #print("[+]", perm, " found.")
                found_api_signatures.append(api_call)
    for api_call in api_call_signatures:
        if api_call in found_api_signatures:
            test_df[api_call] = 1
        else:
            test_df[api_call] = 0

    for intent_filter in intent_filters:
        action_elements = intent_filter.findall(".//action")
        for action_element in action_elements:
            action_value = action_element.get("{http://schemas.android.com/apk/res/android}name")
            for intent in intents:
                if re.search(intent, action_value):
                    found_intents.append(intent)
    for intent in intents:
        if intent in found_intents:
            test_df[intent] = 1
        else:
            test_df[intent] = 0
    for method in d.get_methods():
        for keyword in keywords:
            try:
                if re.search(keyword, method.get_code().get_instruction()):
                    found_keywords.append(keyword)
            except:
                pass
    for keyword in keywords:
        if keyword in found_keywords:
            test_df[keyword] = 1
        else:
            test_df[keyword] = 0
    # Construct the DataFrame
    
    return test_df

@app.route('/')
def index():
    return "Hello world"

@app.route('/predict', methods=['POST'])
def predict():
    feature_df = pd.read_csv("F:/Downloads/archive/dataset-features-categories.csv", header=None, names=["X", "Category"])
    data = pd.read_csv("F:/Downloads/archive/drebin-215-dataset-5560malware-9476-benign.csv", encoding="utf-8", low_memory=False, na_values="?")
    file = request.files['file']
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'})

   
    if file.filename == '':
        return jsonify({'error': 'No selected file'})

    if file:
        # Ensure that the 'uploads' directory exists
        if not os.path.exists('uploads'):
            os.makedirs('uploads')

        # Save the uploaded file
        file_path = 'uploads/' + file.filename
        file.save(file_path)

        # Extract features from the uploaded APK file
        test_df = extract_features(file_path, feature_df,data)

        # Drop unnecessary columns
        dropped = test_df.drop(["filename","class"], axis=1)
        

        # Make predictions using the Random Forest model
        prediction = rf_model.predict(dropped)

        # Return the prediction
        return jsonify({'prediction': str(prediction)})

if __name__ == '__main__':
    app.run(debug=False,host='0.0.0.0')
